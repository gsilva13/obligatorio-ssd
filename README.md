# Obligatorio IA - Sistemas de soporte de decisiÃ³n
Realizado por:
- Fernando Spillere - 274924
- Guillermo Silva - 210802
- Gimena AlamÃ³n - (nro de Estudiante)

## ğŸ¤– Tienda Alemana - Chatbot RAG

Sistema de chatbot inteligente para Tienda Alemana con arquitectura RAG (Retrieval-Augmented Generation) que responde preguntas sobre productos, precios, ubicaciones y sucursales basÃ¡ndose en documentos PDF.

## ğŸ—ï¸ Arquitectura del Proyecto

```
obligatorio-ssd/
â”œâ”€â”€ Backend/          # API Node.js + LangChain + Ollama + RAG
â””â”€â”€ Frontend/         # Interfaz web del chatbot (React/Vue/etc)
```

## ğŸ“‹ Prerrequisitos

- **Node.js** (v18 o superior)
- **Ollama** instalado en el sistema
- **Git** para clonar el repositorio

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Clonar el Repositorio

```bash
git clone <repository-url>
cd obligatorio-ssd
```

### 2. Configurar el Backend

#### 2.1. Instalar Ollama

**En Windows:**

```bash
# Descargar e instalar desde: https://ollama.ai/download
# O usar winget:
winget install Ollama.Ollama
```

**En Linux/macOS:**

```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

#### 2.2. Descargar Modelos de IA

```bash
# Iniciar Ollama (en una terminal separada)
ollama serve

# En otra terminal, descargar los modelos necesarios:
ollama pull llama3.2:1b          # Modelo de chat (1.3GB)
ollama pull nomic-embed-text     # Modelo de embeddings (274MB)

# Verificar que se descargaron correctamente
ollama list
```

#### 2.3. Instalar Dependencias del Backend

```bash
cd Backend
npm install
```

#### 2.4. Configurar Variables de Entorno

```bash
# Copiar archivo de configuraciÃ³n
cp .env.example .env

# El archivo .env ya tiene la configuraciÃ³n por defecto:
# PORT=3001
# OLLAMA_BASE_URL=http://127.0.0.1:11434
# OLLAMA_MODEL=llama3.2:1b
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text
```

#### 2.5. Preparar Documentos PDF

```bash
# Los PDFs de ejemplo ya estÃ¡n en la carpeta correcta
# Si quieres agregar tus propios PDFs:
# - Copia los archivos PDF a: Backend/data/pdfs/
# - Los archivos deben contener informaciÃ³n sobre productos, precios, ubicaciones

# Verificar que los PDFs estÃ©n en su lugar
ls Backend/data/pdfs/
```

#### 2.6. Configurar Vector Store (Base de Datos de Documentos)

```bash
# Este comando procesa los PDFs y crea la base de datos vectorial
# Asegurarse de estar en el directorio OBLIGATORIO-SSD/backend/
npm run setup-vector-store
```

#### 2.7. Iniciar el Backend

```bash
# Ejecutar en modo desarrollo (con auto-reload)
npm run dev

# El servidor estarÃ¡ disponible en: http://localhost:3001
```

### 3. Configurar el Frontend

```bash
# Cambiar al directorio del frontend
cd ../Frontend

# Instalar dependencias
npm install

# Iniciar el frontend
npm start

# El frontend estarÃ¡ disponible en: http://localhost:3000 (o el puerto que se configure)
```

## ğŸ¯ Verificar que Todo Funciona

### 1. Verificar Backend

```bash
# Test de salud del servidor
curl http://localhost:3001/api/health

# Test de diagnÃ³stico completo
curl http://localhost:3001/api/chat/diagnose

# Test de chat
curl -X POST http://localhost:3001/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Â¿QuÃ© productos tienes disponibles?"}'
```

### 2. Verificar Frontend

- Abrir http://localhost:3000 en el navegador
- DeberÃ­a mostrar la interfaz del chatbot
- Probar enviar un mensaje como: "Â¿CuÃ¡nto cuesta la leche?"

## ğŸ’¬ Ejemplos de Preguntas para Probar

### Consultas sobre Productos y Precios

- "Â¿CuÃ¡nto cuesta la leche de 1 litro?"
- "Â¿QuÃ© productos tienes disponibles?"
- "Â¿Tienen stock de yogur de frutilla?"
- "Â¿CuÃ¡l es el precio del jugo de naranja?"

### Consultas sobre Ubicaciones

- "Â¿DÃ³nde encuentro el arroz en la tienda?"
- "Â¿En quÃ© gÃ³ndola estÃ¡ el detergente?"
- "Â¿QuÃ© productos hay en la secciÃ³n de lÃ¡cteos?"

### Consultas sobre Sucursales

- "Â¿CuÃ¡les son los horarios de atenciÃ³n?"
- "Â¿DÃ³nde estÃ¡ ubicada la sucursal principal?"
- "Â¿QuÃ© dÃ­as estÃ¡n abiertos?"

## ğŸš¨ SoluciÃ³n de Problemas Comunes

### Error: No se puede conectar a Ollama

```bash
# Verificar que Ollama estÃ© ejecutÃ¡ndose
ollama serve

# En otra terminal, verificar que responda
curl http://localhost:11434/api/version
```

### Error: Modelos no encontrados

```bash
# Verificar que los modelos estÃ©n descargados
ollama list

# Si no estÃ¡n, descargarlos
ollama pull llama3.2:1b
ollama pull nomic-embed-text
```

### Error: Vector store no encontrado

```bash
cd Backend
npm run setup-vector-store
```

### Error: Puerto ocupado

```bash
# Si el puerto 3001 estÃ¡ ocupado, cambiar en Backend/.env:
# PORT=3002

# Si el puerto 3000 estÃ¡ ocupado para el frontend, generalmente
# el sistema preguntarÃ¡ si usar otro puerto automÃ¡ticamente
```

## ğŸ“ Estructura de Archivos Importante

```
Backend/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pdfs/             # Documentos PDF del negocio
â”‚   â””â”€â”€ vector-store/     # Base de datos vectorial (se crea automÃ¡ticamente)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ server.js         # Servidor principal
â”‚   â”œâ”€â”€ routes/           # Endpoints de la API
â”‚   â””â”€â”€ services/         # LÃ³gica de negocio (RAG, Chat)
â”œâ”€â”€ .env                  # Variables de configuraciÃ³n
â””â”€â”€ package.json

Frontend/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ (archivos del frontend)
â”œâ”€â”€ package.json
â””â”€â”€ (archivos de configuraciÃ³n del framework usado)
```

## ğŸ› ï¸ Comandos Ãštiles

### Backend

```bash
cd Backend
npm run dev              # Desarrollo con auto-reload
npm start               # ProducciÃ³n
npm run setup-vector-store  # Recrear base de datos de documentos
```

### Frontend

```bash
cd Frontend
npm start               # Iniciar frontend
npm run build          # Build para producciÃ³n
```

## ğŸ“š MÃ¡s InformaciÃ³n

- **Backend**: Ver `Backend/README.md` para documentaciÃ³n tÃ©cnica completa
- **API Endpoints**: http://localhost:3001/api/ (cuando el backend estÃ© ejecutÃ¡ndose)
- **Logs**: Los logs del backend se guardan en `Backend/logs/`

## ğŸ‰ Â¡Listo para Usar!

Una vez completados estos pasos, tendrÃ¡s:

- âœ… Backend ejecutÃ¡ndose en http://localhost:3001
- âœ… Frontend ejecutÃ¡ndose en http://localhost:3000
- âœ… Chatbot funcional con informaciÃ³n real de los PDFs
- âœ… Sistema RAG completamente operativo

Â¡El chatbot estÃ¡ listo para responder preguntas sobre Tienda Alemana!
